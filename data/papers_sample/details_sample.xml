<N20015>
    <A250 valueType="4">0</A250>
    <N23009>
        <N23009>
            <A3010 valueType="7">abstract1</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">subject</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">science</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">degree</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">replyDate</A3010>
            <A3011 valueType="2">D</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">secret</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">foreignSubject</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">tutorName1</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">tutorUnits1</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">tutorName2</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">tutorUnits2</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">length</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">referLength</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">abstract2</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">research</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">country</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">audit</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">views</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">listing</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">school</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">scanNumber</A3010>
            <A3011 valueType="2">Z</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">schoolID</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">keyword2</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">tutorname3</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">tutorunits3</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">name</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">college1</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">professname</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">refer</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">listry</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">RUID</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">keyword1</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">paperState</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">PERMISSIONTYPE</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">STATEFLAG</A3010>
            <A3011 valueType="2">Z</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">_102c9401000086XXXX_0</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">_10c6c679000016XXXX_1</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">_102aef92000048XXXX_2</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <N23009>
            <A3010 valueType="7">_119ebc470009c6c351_3</A3010>
            <A3011 valueType="2">C</A3011>
        </N23009>
        <A3003 valueType="4">1</A3003>
    </N23009>
    <N23008>
        <N23008>
            <A3015 valueType="7">
                随着互联网和多媒体技术的不断发展，图像与文本已经成为不可或缺的信息载体。每天互联网上都会产生海量的图像与文本数据，如何对它们进行有效地管理成为了人们迫切需要解决的问题。面对海量的数据，传统的人工标注的管理方式不仅耗时而且耗力。于是，本文针对目前存在于图像和文本内容理解中的问题，提出了若干机器学习的算法，旨在能让计算机更加智能化的自动进行图像和文本数据的管理。本文中所指的图像内容理解主要指的图像分类和图像语义自动标注技术，文本内容理解是指文本的信息抽取技术。事实上，无论是图像语义分析还是文本信息抽取，最终都可以建模为模式识别的问题。图像和文本只是信息的传播媒介，而对机器而言，低层特征才是它能理解的语言。换言之，本文始终围绕着的一个中心思想就是如何利用机器学习算法更好地构建低层特征到高层语义之间的映射关系。以此为中心，本文的主要研究内容包括：
                1. 提出了一种多尺度融合的低层特征构造方法。算法首先基于传统的BOW (Bag-of-words)模型通过对不同尺度下的图像进行稠密采样获取视觉词，然后通过pLSA (probabilistic
                Latent Semantic
                Analysis)算法获取不同尺度的图像的主题模型，接着采用简单的级联操作将特征拼接起来作为图像的特征表示。在实验中，通过与在单一尺度下进行特征提取的算法进行对比，证明了本方法的有效性。
                2. 提出一种优化SVM (Support Vector
                Machine)训练数据集的方法。当我们对训练图像进行稠密采样及特征提取后，将会产生许多训练样本。实际上，每幅图像都包含了很多重复的特征点以及一部分离群点（outliers），其中包含了冗余和噪音信息。因此，如果用所有的特征点对SVM分类器进行训练的话，将会非常耗时甚至可能影响到分类精度。相反地，如果我们从这些海量数据中挑选出一部分代表点作为SVM的训练样本，则不仅会加速训练过程，而且有可能提升分类精度。基于此，我们首先使用LVQ
                (Learning Vector Quantization)对训练数据进行约简，然后再通过SVM进行图像语义标注。实验发现基于AP (Affinity Propagation)算法的LVQ比基于SOM
                (Self-Organizing Map)网络的LVQ无论在时间开销还是在样本点选取的有效性方面都更胜一筹。
                3. 提出一种全新的基于低秩和局部编码的图像分类算法Locality-constrained Low-rank
                Coding，缩写为LCLR。LCLR通过联合编码和局部约束，很好地把握了流形特征空间的特点。相比于其他的基于低秩编码的策略，LCLR没有选择?
                1范数作为正则项，而是选择了效果更好的局部约束项。大量的实验也验证了LCLR算法的有效性。同时，为了解决该算法在优化时遇到的问题，我们也提出了一种基于在线学习的优化策略。实验证明，LCLR算法在很多标准数据集上的效果达到了世界一流水平。
                4.
                提出了一种无监督的，对搜索日志进行自动挖掘可比较实体对的抽取算法。算法通过对包含10亿条英文搜索词条的搜索日志进行信息抽取，最终构建了一个包含630,121个实体顶点以及300万条边的可比较实体图。在实验部分，我们充分且详细地验证了所提出的算法以及所构建的图。据我们所知，这个图是目前最大的关于可比较关系的拓扑图。
                5.
                在以往的研究中，文本库都是事先给定的，这使得人们更加注重对信息抽取算法本身的研究而忽略了文本库的重要性。事实上，文本库的质量将会对信息抽取算法的效果产生很大的影响。为了进一步提高信息抽取算法的效果，本文提出一种构建大规模高质量文本库的算法。我们将互联网上所有的网页按照他们的知识含量由高到低进行排序，然后优先对排名靠前的网页进行信息抽取。实验证明，常用的信息抽取算法在本文提出的算法所构建的文本库上能取得更好的效果。
            </A3015>
            <A3015 valueType="7">特征构建算法及其在图像语义标注与信息抽取中的应用研究</A3015>
            <A3015 valueType="7">计算机科学与技术</A3015>
            <A3015 valueType="7">208</A3015>
            <A3015 valueType="7">2015-06-09</A3015>
            <A3015 valueType="7">公开</A3015>
            <A3015 valueType="7">A study on feature design algorithms with application to image annotation and
                information extraction
            </A3015>
            <A3015 valueType="7">郭平</A3015>
            <A3015 valueType="7">计算机学院</A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7">130</A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7">With the development of WWW and multimedia technologies, images and texts have become
                indispensable information carriers. There are a large scale of images and texts data generated everyday
                on the Internet. Hence, how to effectively manage them becomes an urgent task. Facing these voluminous
                data, traditional method of human labeling is not only time-consuming but also label intensive. Aiming
                at the problems exsited in current image and text understanding algorithms, this paper proposes several
                machine learning algorithms to make image and text data management more intelligent. In this paper,
                image understanding mainly focus on image classification and automatic image annotation, while text
                understanding stands for information extraction. In fact, no matter for image semantic analysis or
                information extraction from texts, they both can be deduced to the problem of pattern recognition.
                Images and texts are just the media, and low level features are the real language that computers can
                understand. In other words, this paper concentrates on a sole topic, which is how to build a better
                mapping function from low level features to high lever semantics by using machine learning algorithms.
                The main work of this paper is as follows:
                1.A multi-scale low level feature fusion framework is proposed. The algorithm first uses the traditional
                BOW model at different scales to extract densly sampled visual words. Then topics from different scales
                can be obtained by using pLSA algorithm. In the next, this paper propose to concatenate the features
                into a new feature vector. In the experiment, by comparing with single scale feature extraction methods,
                the proposed method demonstrates its superiority.
                2.A training data optimization method is proposed. By dense sampling and feature extraction, lots of
                feature points will be generated. Actually, every image contains many repeated features and outliers,
                where redundant and noisy information are included. Hence, if we use all the feature points to train SVM
                (Support Vector Machine) classifiers, it will be time-consuming and moreover, it may deteriorate the
                classification performance. On the contrary, if we can select some representative points as the training
                data for SVM, it will not only accelerate the training speed but also improve the accuracy. For this
                reason, this paper proposes to first use LVQ technique to do training data optimization, and then use
                SVM to do image annotation. From the experiments, we found that AP-based LVQ is better than SOM-based
                LVQ in terms of both the representativeness of the chosen feature point and the classification precision
                of the trained SVM.
                3.A locality-constrained low-rank (LCLR) coding algorithm is proposed for image classification. LCLR can
                exploit the manifold of feature space by using joint coding and locality constraint. Compared to other
                low-rank based paradigms, LCLR uses locality regularization term instead of widely used ? 1 norm.
                Extensive experiments have been carried out to demonstrate that LCLR outperforms other state-of-the-art
                algorithms.
                4.A fully unsupervised information extraction algorithm has been proposed to automatically discover
                comparable entities in the query log. By using the proposed algorithm on 1 billion search queries, we
                finally built a comparable entity graph containing 630,121 vertexes (entities) and 300 million edges. In
                the experiment, we examined the proposed algorithm and the built graph thoroughly. As far as we know,
                the graph is the largest topology in terms of the relation comparability.
                5.In the research of information extraction (IE), text corpus is given in advance. In this sense, people
                pay more attention to the IE algorithm rather than the importance of the given text corpus. In fact, the
                quality of the text corpus will greatly affect the performance of the IE algorithms. In order to improve
                the performance of current IE algorithms, this paper presents an algorithm to construct a large-scale
                and high-quality text corpus. We rank all the web pages on the Internet by their knowledge, and then
                extract knowledge from top to down. From the experiments, we found that the performance of both relation
                specific information extraction and open information extraction algorithms can be boosted.
            </A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7">中国</A3015>
            <A3015 valueType="7">审核合格</A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7">北京理工大学</A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7">100071</A3015>
            <A3015 valueType="7">open information extraction; relation specific information extraction; random walk
                algorithm; page rank; image automatic annotation; image classification; bag of visual words; low-rank
                coding
            </A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7">姜子恒</A3015>
            <A3015 valueType="7">1426443f000007c351</A3015>
            <A3015 valueType="7">计算机软件与理论</A3015>
            <A3015 valueType="7">[1] Agichtein E, Gravano L. Snowball: Extracting relations from large plain-text
                collections[C]. Proceedings of the fifth ACM conference on Digital libraries. ACM, 2000: 85-94.
                [2] Carlson A, Betteridge J, Kisiel B, et al. Toward an Architecture for Never-Ending Language
                Learning[C]. AAAI. 2010, 5: 3.
                [3] Fader A, Soderland S, Etzioni O. Identifying relations for open information extraction[C].
                Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for
                Computational Linguistics, 2011: 1535-1545.
                [4] Bollegala D T, Matsuo Y, Ishizuka M. Relational duality: Unsupervised extraction of semantic
                relations between entities on the web[C]. Proceedings of the 19th international conference on World wide
                web. ACM, 2010: 151-160.
                [5] Berry M W. Survey of text mining[J]. Computing Reviews, 2004, 45(9): 548.
                [6] Toutanova K, Klein D, Manning C D, et al. Feature-rich part-of-speech tagging with a cyclic
                dependency network[C]. Proceedings of the 2003 Conference of the North American Chapter of the
                Association for Computational Linguistics on Human Language Technology-Volume 1. Association for
                Computational Linguistics, 2003: 173-180.
                [7] Klein D, Manning C D. Fast exact inference with a factored model for natural language parsing[C].
                Advances in neural information processing systems. 2002: 3-10.
                [8] McCallum A, Li W. Early results for named entity recognition with conditional random fields, feature
                induction and web-enhanced lexicons[C]. Proceedings of the seventh conference on Natural language
                learning at HLT-NAACL 2003-Volume 4. Association for Computational Linguistics, 2003: 188-191.
                [9] Srihari R, Li W. Information Extraction Supported Question Answering[J]. In Proceedings of the
                Eighth Text REtrieval Conference (TREC-8, 1999:185--196.
                [10] Jijkoun V, Rijke M D, Mur J. Information Extraction for Question Answering: Improving Recall
                Through Syntactic Patterns[J]. In Coling 2004, 2004:1284--1290.
                [11] Song M, Song I Y, Allen R B, et al. Keyphrase extraction-based query expansion in digital
                libraries[C]. Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries. ACM, 2006:
                202-209.
                [12] Soderland S G. Building a Machine Learning Based Text Understanding System[J]. In Proc. IJCAI-2001
                Workshop on Adaptive Text Extraction and Mining, 2001:64--70.
                [13] Hobbs J R. Information extraction from biomedical text[J]. Journal of Biomedical Informatics, 2002,
                35(4):260-264.
                [14] Shi J, Li Y, Zhu J, et al. Joint sparse coding based spatial pyramid matching for classification of
                color medical image[J]. Computerized Medical Imaging and Graphics, 2014.
                [15] Javidi B. Image recognition and classification: algorithms, systems, and applications[M]. CRC
                Press, 2002.
                [16] 高隽,谢昭.图像理解理论与方法[M]. 北京：科学出版社，2009.
                [17] Cusano C, Ciocca G, Schettini R. Image annotation using SVM[C]. Electronic Imaging 2004.
                International Society for Optics and Photonics, 2003: 330-338.
                [18] Chapelle O, Haffner P, Vapnik V N. Support vector machines for histogram-based image
                classification[J]. Neural Networks, IEEE Transactions on, 1999, 10(5): 1055-1064.
                [19] Goh K S, Chang E Y, Li B. Using one-class and two-class SVMs for multiclass image annotation[J].
                Knowledge and Data Engineering, IEEE Transactions on, 2005, 17(10): 1333-1346.
                [20] Qi X, Han Y. Incorporating multiple SVMs for automatic image annotation[J]. Pattern Recognition,
                2007, 40(2): 728-741.
                [21] Duygulu P, Barnard K, Freitas N, Forsyth D. Object recognition as machine translation: learning a
                lexicon for a fixed image vocabulary.In: Proc of European Conference on Computer Vision(ECCV’02),
                Copenhagen, Denmark, May.2002:97-112.
                [22] Barnard K, Duygulu P, Freitas N, Forsyth D, Blei D, Jordan M I. Matching words and Pietures.
                Journal of Maehine Learning Research, 2003, 3:1107-1135.
                [23] Jeon J, Lavrenko V, Manmatha R. Automatic image annotation and retrieval using cross-media
                relevance models. In: Proc. Of Int. ACM SIGIR Conf. on Research and Development in Information
                Retrieval(ACM SIGIR’03), Toronto, Canada, Jul.2003: 119-126.
                [24] Wang J, Yang J, Yu K, et al. Locality-constrained Linear Coding for image classification[J]. 2013
                IEEE Conference on Computer Vision and Pattern Recognition, 2010, 119(5):3360-3367.
                [25] Yang J, Yu K, Gong Y, et al. Linear spatial pyramid matching using sparse coding for image
                classification[C]. Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE,
                2009:1794 - 1801.
                [26] 李保利, 陈玉忠. 信息抽取研究综述[J]. 计算机工程与应用, 2003, 39(10):1-5.
                [27] Borthwick A. A Maximum Entropy Approach to Named Entity Recognition[J]. Dissertation Abstracts
                International, Volume: 60-09, Section: B, page: 4701.;Adviser: Ralph Grishma, 1999.
                [28] Xu G, Yang S H, Li H. Named entity mining from click-through data using weakly supervised latent
                dirichlet allocation[C]. Proceedings of the 15th ACM SIGKDD international conference on Knowledge
                discovery and data mining. ACM, 2009: 1365-1374.
                [29] Guo J, Xu G, Cheng X, et al. Named entity recognition in query[C]. Proceedings of the 32nd
                international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009:
                267-274.
                [30] Zelenko D, Aone C, Richardella A. Kernel Methods for Relation Extraction[J]. Journal of Machine
                Learning Research, 2002, 3(6):1083-1106.
                [31] Mintz M, Bills S, Snow R, et al. Distant supervision for relation extraction without labeled
                data[C]. Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th
                International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2.
                Association for Computational Linguistics, 2009: 1003-1011.
                [32] Ritter A, Etzioni O, Clark S. Open domain event extraction from twitter[C]. Proceedings of the 18th
                ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2012: 1104-1112.
                [33] Rattenbury T, Good N, Naaman M. Towards Automatic Extraction Of Event And Place Semantics From
                Flickr Tags[C]. SIGIR '07 Proceedings of the 30th annual international ACM SIGIR conference on Research
                and developm, 2007.
                [34] Bj?rne J, Salakoski T. Generalizing biomedical event extraction[J]. In Proceedings of BioNLP’11,
                2011.
                [35] Vapnik V. The nature of statistical learning theory[M]. Springer Science &amp; Business Media,
                2000.
                [36] 车万翔, 刘挺, 李生. 实体关系自动抽取[C]. 全国信息检索与内容安全学术会议. 2004:1-6.
                [37] Bishop C M. Pattern Recognition and Machine Learning[J]. Company, New York, NY, 2006, (4):049901.
                [38] Kambhatla N. Combining lexical, syntactic, and semantic features with maximum entropy models for
                extracting relations[J]. Proceedings of ACL’04, 2004.
                [39] Zhao S, Grishman R. Extracting relations with integrated information using kernel methods[J]. In
                Proceedings of the annual meeting of ACL, 2005:419--426.
                [40] Lodhi H, Saunders C, Shawe-Taylor J, et al. Text Classification using String Kernels[J]. Journal of
                Machine Learning Research, 2002, 2(3):563--569.
                [41] Bunescu R C, Mooney R J, Bunescu R C, et al. Subsequence Kernels for Relation Extraction.[J]. NIPS,
                2005.
                [42] Culotta A. Dependency tree kernels for relation extraction[J]. In Proceedings of the 42nd Annual
                Meeting of the Association for Computational Linguistics (ACL-04, 2004:423--429.
                [43] Brin S. Extracting Patterns and Relations from the World Wide Web[J]. In WebDB Workshop at 6th
                International Conference on Extending Database Technology, EDBT’98, 1998:172--183.
                [44] Etzioni O, Cafarella M, Downey D, et al. Web-scale information extraction in knowitall:(preliminary
                results)[C]. Proceedings of the 13th international conference on World Wide Web. ACM, 2004: 100-110.
                [45] Zhu J, Nie Z, Liu X, et al. StatSnowball: a statistical approach to extracting entity
                relationships[C]. Proceedings of the 18th international conference on World wide web. ACM, 2009:
                101-110.
                [46] Banko M, Cafarella M J, Soderland S, et al. Open information extraction for the web[C]. IJCAI.
                2007, 7: 2670-2676.
                [47] Banko M, Etzioni O, Center T. The Tradeoffs Between Open and Traditional Relation Extraction[C].
                ACL. 2008, 8: 28-36.
                [48] www.wikipedia.org
                [49] Suchanek F M, Kasneci G, Weikum G. Yago: A Large Ontology from Wikipedia and WordNet[J]. Web
                Semantics: Science, Services and Agents on the World Wide Web, 2007, 6(2008):203–217.
                [50] Wu F, Weld D S. Open information extraction using Wikipedia[C]. Proceedings of the 48th Annual
                Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,
                2010: 118-127.
                [51] Miller G A. WordNet: a lexical database for English[J]. Communications of the ACM, 1995, 38(11):
                39-41.
                [52] Lafferty J, Mccallum A, Pereira F. F.: Conditional random fields: Probabilistic models for
                segmenting and labeling sequence data[J]. In: Proc. 18th International Conf. on Machine Learning, 2001.
                [53] Wang, J.Z., et al. "SIMPLIcity: semantics-sensitive integrated matching for picture libraries."
                Pattern Analysis and Machine Intelligence, IEEE Transactions on 23.9(2001):947 - 963.
                [54] Datta R, Joshi D, Li J, et al. Image retrieval: Ideas, influences, and trends of the new age[J].
                ACM Computing Surveys (CSUR), 2008, 40(2): 5.
                [55] Chang S K, Hsu A. Image information systems: where do we go from here?[J]. IEEE transactions on
                Knowledge and Data Engineering, 1992, 4(5): 431-442.
                [56] Jain A K, Vailaya A. Image retrieval using color and shape[J]. Pattern recognition, 1996, 29(8):
                1233-1244.
                [57] Vasconcelos, N. "Minimum probability of error image retrieval." Signal Processing, IEEE
                Transactions on 52.8(2004):2322 - 2336.
                [58] Rasiwasia N, Vasconcelos N, Moreno P J. Query by semantic example[M]. Image and Video Retrieval.
                Springer Berlin Heidelberg, 2006: 51-60.
                [59] Huang J, Kumar S R, Mitra M, et al. Image indexing using color correlograms[C]. Computer Vision and
                Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on. IEEE, 1997: 762-768.
                [60] Chang S K, Yan C W, Dimitroff D C, et al. An intelligent image database system[J]. Software
                Engineering, IEEE Transactions on, 1988, 14(5): 681-688.
                [61] Dowe J. Content-based retrieval in multimedia imaging[C]. IS&amp;T/SPIE's Symposium on Electronic
                Imaging: Science and Technology. International Society for Optics and Photonics, 1993: 164-167.
                [62] Sivic J, Zisserman A. Video Google: A text retrieval approach to object matching in videos[C].
                Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on. IEEE, 2003: 1470-1477.
                [63] Yang N C, Chang W H, Kuo C M, et al. A fast MPEG-7 dominant color extraction with new similarity
                measure for image retrieval[J]. Journal of Visual Communication and Image Representation, 2008, 19(2):
                92-105.
                [64] Islam M M, Zhang D, Lu G. A geometric method to compute directionality features for texture
                images[C]. Multimedia and Expo, 2008 IEEE International Conference on. IEEE, 2008: 1521-1524.
                [65] Islam M M, Zhang D, Lu G. Automatic categorization of image regions using dominant colour based
                vector quantization, in: Proceedings of the Digital Image Computing: Techniques and Applications,
                Canberra, Australia, December 1–3, 2008, pp. 191–198.
                [66] Szummer M., Picard R.W. Indoor–outdoor image classification, in: Proceedings of the IEEE
                International Workshop on Content-Based Access of Image and Video Databases, January 1998.
                [67] Mori Y, Takahashi H, Oka R. Image-to-word transformation based on dividing and vector quantizing
                images with words[C]. First International Workshop on Multimedia Intelligent Storage and Retrieval
                Management. 1999.
                [68] Town C, Sinclair D. Content based image retrieval using semantic visual categories[J]. TR2000-14,
                AT&amp;T Labs Cambridge, 2000.
                [69] A. Vailaya, M.A.T. Figueiredo, A.K. Jain, H.J. Zhang, Image classification for content-based
                indexing, IEEE Transactions on Image Processing 10 (1) (2001) 117–130.
                [70] Duygulu P, Barnard K, de Freitas J F G, et al. Object recognition as machine translation: Learning
                a lexicon for a fixed image vocabulary[M]. Computer Vision—ECCV 2002. Springer Berlin Heidelberg, 2002:
                97-112.
                [71] Chang E, Goh K, Sychay G, et al. CBSA: content-based soft annotation for multimodal image retrieval
                using Bayes point machines[J]. Circuits and Systems for Video Technology, IEEE Transactions on, 2003,
                13(1): 26-38.
                [72] Zhang D, Monirul Islam M, Lu G. A review on automatic image annotation techniques[J]. Pattern
                Recognition, 2012, 45(1):346–362.
                [73] Fan J, Gao Y, Luo H, et al. Automatic image annotation by using concept-sensitive salient objects
                for image content representation[C]. Proceedings of the 27th annual international ACM SIGIR conference
                on Research and development in information retrieval. ACM, 2004: 361-368.
                [74] Feng S L, Manmatha R, Lavrenko V. Multiple bernoulli relevance models for image and video
                annotation[C]. Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE
                Computer Society Conference on. IEEE, 2004, 2: II-1002-II-1009 Vol. 2.
                [75] Carneiro G, Chan A B, Moreno P J, et al. Supervised learning of semantic classes for image
                annotation and retrieval[J]. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2007,
                29(3): 394-410.
                [76] Maree R, Geurts P, Piater J, et al. Random subwindows for robust image classification[C]. Computer
                Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. IEEE, 2005, 1:
                34-40.
                [77] Li J, Wang J Z. Real-time computerized annotation of pictures[J]. Pattern Analysis and Machine
                Intelligence, IEEE Transactions on, 2008, 30(6): 985-1002.
                [78] Wang C, Jing F, Zhang L, et al. Image annotation refinement using random walk with restarts[C].
                Proceedings of the 14th annual ACM international conference on Multimedia. ACM, 2006: 647-650.
                [79] Wang C, Jing F, Zhang L, et al. Scalable search-based image annotation of personal images[C].
                Proceedings of the 8th ACM international workshop on Multimedia information retrieval. ACM, 2006:
                269-278.
                [80] Wang X J, Zhang L, Jing F, et al. Annosearch: Image auto-annotation by search[C]. Computer Vision
                and Pattern Recognition, 2006 IEEE Computer Society Conference on. IEEE, 2006, 2: 1483-1490.
                [81] Wang C, Jing F, Zhang L, et al. Content-based image annotation refinement[C]. Computer Vision and
                Pattern Recognition, 2007. CVPR'07. IEEE Conference on. IEEE, 2007: 1-8.
                [82] Liu J, Wang B, Lu H, et al. A graph-based image annotation framework[J]. Pattern Recognition
                Letters, 2008, 29(4): 407-415.
                [83] Lu Y, Zhang L, Tian Q, et al. What are the high-level concepts with small semantic gaps?[C].
                Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on. IEEE, 2008: 1-8.
                [84] Wang C, Zhang L, Zhang H J. Learning to reduce the semantic gap in web image retrieval and
                annotation[C]. Proceedings of the 31st annual international ACM SIGIR conference on Research and
                development in information retrieval. ACM, 2008: 355-362.
                [85] Wang C, Zhang L, Zhang H J. Scalable Markov model-based image annotation[C]. Proceedings of the
                2008 international conference on Content-based image and video retrieval. ACM, 2008: 113-118.
                [86] Shi R, Feng H, Chua T S, et al. An adaptive image content representation and segmentation approach
                to automatic image annotation[M]. Image and Video Retrieval. Springer Berlin Heidelberg, 2004: 545-554.
                [87] 刘峡壁. 人工智能导论-方法与系统[M]. 北京：国防工业出版社, 2008.
                [88] Lavrenko V, Manmatha R, Jeon J. A model for learning the semantics of Pietures. In: Proc. of
                Advances in Neural information processing Systems(NIPS’03), 2003.
                [89] Hofmann T. Unsupervised learning by probabilistic latent semantic analysis[J]. Machine learning,
                2001, 42(1-2): 177-196.
                [90] Blei D M, Ng A Y, Jordan M I. Latent dirichlet allocation[J]. the Journal of machine Learning
                research, 2003, 3: 993-1022.
                [91] Blei D M, Jordan M I. Modeling annotated data[C]. Proceedings of the 26th annual international ACM
                SIGIR conference on Research and development in informaion retrieval. ACM, 2003: 127-134.
                [92] Monay F, Gati ca??Perez D . Modeling semantic aspects for cross-media image indexing. IEEE
                Transactions on Pattern Analysis and Machine Intelligence, 2007, 29(10): 1802-1817
                [93] Quelhas P, Monay F, Odobez J M, et al. A thousand words in a scene[J]. Pattern Analysis and Machine
                Intelligence, IEEE Transactions on, 2007, 29(9): 1575-1589.
                [94] Li Z, Shi Z, Liu X, Shi ZZ. Modeling continuous visual features for semantic image annotation and
                retrieval. Pattern Recognition Letters, 2011, 32: 516–523.
                [95] Xiang, Yu, et al. "A revisit of Generative Model for Automatic Image Annotation using Markov Random
                Fields.." Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on (2009):1153 -
                1160.
                [96] Yang, Qiang, et al. "Heterogeneous Transfer Learning for Image Clustering via the Social Web." ACL
                '09 Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th Intern
                1(2009).
                [97] Qi, Guo-Jun et al. Towards semantic knowledge propagation from text corpus to web images. WWW’2011,
                297-306.
                [98] Jin, Y., Khan, L., Wang, L., 2005. Image annotations by combining multiple evidence wordnet. In:
                Proc. 13th Ann. ACM Internat. Conf. on Multimedia, pp. 706–715.
                [99] Tao W, Jin H, Zhang Y. Color image segmentation based on mean shift and normalized cuts[J].
                Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on, 2007, 37(5): 1382-1389.
                [100] Shi J, Malik J. Normalized cuts and image segmentation[J]. Pattern Analysis and Machine
                Intelligence, IEEE Transactions on, 2000, 22(8): 888-905.
                [101] Felzenszwalb.P.F, Huttenlocher.D.P. Efficient graph-based image segmentation. International
                Journal of Computer Vision [J]. 59(2):167–181, 2004.
                [102] Harris C, Stephens M. A combined corner and edge detector[J]. In Proc. of Fourth Alvey Vision
                Conference, 1988:147--151.
                [103] Lowe D G. Distinctive image features from scale-invariant keypoints[J]. International journal of
                computer vision, 2004, 60(2): 91-110.
                [104] Bay H, Tuytelaars T, Gool L V. Surf: Speeded up robust features[J]. In ECCV, 2006, (3):404--417.
                [105] Liu L, Wang L, Liu X. In defense of soft-assignment coding[J]. Computer Vision (ICCV), 2011 IEEE
                International Conference on, 2011, 24(4):2486 - 2493.
                [106] Flickner M, Sawhney H, Niblack W, et al. Query by image and video content: The QBIC system[J].
                Computer, 1995, 28(9): 23-32.
                [107] Pass G, Zabih R. Histogram refinement for content-based image retrieval[C]. Applications of
                Computer Vision, 1996. WACV'96., Proceedings 3rd IEEE Workshop on. IEEE, 1996: 96-102.
                [108] Long F, Zhang H, Feng D D. Fundamentals of content-based image retrieval[M]. Multimedia
                Information Retrieval and Management. Springer Berlin Heidelberg, 2003: 1-26.
                [109] Gonzalez R.C., Woods R.E. Digital Image Processing, third ed., Prentice-Hall, 2007.
                [110] Tamura H, Mori S, Yamawaki T. Textural features corresponding to visual perception[J]. Systems,
                Man and Cybernetics, IEEE Transactions on, 1978, 8(6): 460-473.
                [111] Park S B, Lee J W, Kim S K. Content-based image classification using a neural network[J]. Pattern
                Recognition Letters, 2004, 25(3): 287-300.
                [112] Zhang R, Zhang Z, Li M, et al. A probabilistic semantic model for image annotation and multimodal
                image retrieval[C]. Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference on. IEEE,
                2005, 1: 846-851.
                [113] Perona P, Malik J. Scale-space and edge detection using anisotropic diffusion[J]. Pattern Analysis
                and Machine Intelligence, IEEE Transactions on, 1990, 12(7): 629-639.
                [114] Lindeberg T. Edge detection and ridge detection with automatic scale selection[J]. International
                Journal of Computer Vision, 1998, 30(2): 117-156.
                [115] Zhang T, Ghanem B, Liu S, et al. Low-rank sparse coding for image classification[C]. Computer
                Vision (ICCV), 2013 IEEE International Conference on. IEEE, 2013: 281-288.
                [116] Lazebnik S, Schmid C, Ponce J. Beyond bags of features: Spatial pyramid matching for recognizing
                natural scene categories[C]. CVPR, 2006, 2: 2169-2178.
                [117] Lu Z, Ip H H S. Image categorization by learning with context and consistency[C]. Computer Vision
                and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE, 2009: 2719-2726.
                [118] Wu L, Hu Y, Li M, et al. Scale-invariant visual language modeling for object categorization[J].
                Multimedia, IEEE Transactions on, 2009, 11(2): 286-294.
                [119] Cao Y, Wang C, Li Z, et al. Spatial-bag-of-features[C]. Computer Vision and Pattern Recognition
                (CVPR), 2010 IEEE Conference on. IEEE, 2010: 3352-3359.
                [120] 张学工. 模式识别[M]. 北京：清华大学出版社, 2008.
                [121] Chen Y, Wang J Z. Image categorization by learning and reasoning with regions[J]. The Journal of
                Machine Learning Research, 2004, 5: 913-939.
                [122] Lu Z, Peng Y, Ip H H S. Image categorization via robust pLSA[J]. Pattern Recognition Letters,
                2010, 31(1): 36-43.
                [123] Abdullah A, Veltkamp R C, Wiering M A. Fixed partitioning and salient points with MPEG-7 cluster
                correlograms for image categorization[J]. Pattern Recognition, 2010, 43(3): 650-662.
                [124] Lin W C, Oakes M, Tait J. Improving image annotation via representative feature vector
                selection[J]. Neurocomputing, 2010, 73(10): 1774-1782.
                [125] Kohonen T. Self-organizing maps[M]. Springer Science &amp; Business Media, 2001.
                [126] Viitaniemi V, Laaksonen J. Evaluating the performance in automatic image annotation: Example case
                by adaptive fusion of global image features[J]. Signal Processing: Image Communication, 2007, 22(6):
                557-568.
                [127] Vailaya A, Figueiredo M A T, Jain A K, et al. Image classification for content-based indexing[J].
                Image Processing, IEEE Transactions on, 2001, 10(1): 117-130.
                [128] Jolliffe I. Principal component analysis[M]. John Wiley &amp; Sons, Ltd, 2002.
                [129] Yang H C, Lee C H. Image semantics discovery from web pages for semantic-based image retrieval
                using self-organizing maps[J]. Expert Systems with Applications, 2008, 34(1): 266-279.
                [130] Jiang Z, He J, Guo P. Feature data optimization with LVQ technique in semantic image
                annotation[C]. Intelligent Systems Design and Applications (ISDA), 2010 10th International Conference
                on. IEEE, 2010: 906-911.
                [131] Frey B J, Dueck D. Clustering by passing messages between data points[J]. Science, 2007,
                315(5814): 972-976.
                [132] Dueck D, Frey B J. Non-metric affinity propagation for unsupervised image categorization[C].
                Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on. IEEE, 2007: 1-8.
                [133] Yang D, Guo P. Improvement of image modeling with affinity propagation algorithm for semantic
                image annotation[C]. Neural Information Processing. Springer Berlin Heidelberg, 2009: 778-787.
                [134] Yang D, Guo P. Image modeling with combined optimization techniques for image semantic
                annotation[J]. Neural Computing and Applications, 2011, 20(7): 1001-1015.
                [135] Choi D I, Park S H. Self-creating and organizing neural networks[J]. Neural Networks, IEEE
                Transactions on, 1994, 5(4): 561-575.
                [136] Martinetz T, Schulten K. A" neural-gas" network learns topologies[M]. University of Illinois at
                Urbana-Champaign, 1991.
                [137] Fritzke.B. Growing cell structures-a self-organizing network for unsupervised and supervised
                learning. Neural networks, 1994. 7(9): pp. 1441-1460.
                [138] Fritzke B. A growing neural gas network learns topologies, in Advances in Neural Information
                Processing System. Cambridge 1995, The MIT Press. pp. 625- 632.
                [139] Blackmore J, Miikkulainen R. Incremental grid growing: encoding high-dimensional structure into a
                two-dimensional feature map. in Proceedings of the IEEE International Conference on Neural Networks.
                1993. pp.450-455
                [140] Chow TWS, Wu S. Cell-splitting grid: a self-creating and self-organizing neural network. Neuro
                computing, 2004. 57: pp. 373-387.
                [141] Sommer, J Bruske; G. Dynamic Cell Structure Learns Perfectly Topology Preserving Map. Neural
                Computation, 1994. 7(4): pp. 845-865.
                [142] Alahakoon D; Halgamuge S K; Srinivasan B. Dynamic selforganizing maps with controlled growth for
                knowledge discovery. IEEE Transactions on Neural Networks, 2000. 11(3): pp. 601-614.
                [143] Kurdthongmee.W. A novel Kohonen SOM-based image compression architecture suitable for moderate
                density FPGAs. Image and Vision Computing, 2008. 26(8): pp. 1094-1105.
                [144] Machón González I; López García H. End-point detection of the aerobic phase in a biological
                reactor using SOM and clustering algorithms. Engineering Applications of Artificial Intelligence, 2006.
                19(1): pp. 19-28.
                [145] Ohmi K. SOM-Based particle matching algorithm for 3D particle tracking velocimetry. Applied
                Mathematics and Computation, 2008. 205(2): pp. 890-898.
                [146] Stanford vision lab, http://vision.stanford.edu/resources_links.html
                [147] VOC2008, http://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2008/
                [148] Guo P, Jia Y, Lyu M R. A study of regularized Gaussian classifier in high-dimension small sample
                set case based on MDL principle with application to spectrum recognition[J]. Pattern Recognition, 2008,
                41(9): 2842-2854.
                [149] Dalal N, Triggs B. Histograms of oriented gradients for human detection[C]. Computer Vision and
                Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. IEEE, 2005, 1: 886-893.
                [150] Wright J, Yang A Y, Ganesh A, et al. Robust face recognition via sparse representation[J]. Pattern
                Analysis and Machine Intelligence, IEEE Transactions on, 2009, 31(2): 210-227.
                [151] Zhang Q, Li B. Discriminative K-SVD for dictionary learning in face recognition[C]. CVPR, 2010:
                2691-2698.
                [152] Mairal J, Ponce J, Sapiro G, et al. Supervised dictionary learning[C]. Advances in neural
                information processing systems. 2009: 1033-1040.
                [153] Mairal J, Bach F, Ponce J, et al. Discriminative learned dictionaries for local image analysis[C].
                Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on. IEEE, 2008: 1-8.
                [154] Chen C F, Wei C P, Wang Y C F. Low-rank matrix recovery with structural incoherence for robust
                face recognition[C]. Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE,
                2012: 2618-2625.
                [155] Zhang Y, Jiang Z, Davis L S. Learning structured low-rank representations for image
                classification[C]. Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on. IEEE, 2013:
                676-683.
                [156] Lee H, Battle A, Raina R, et al. Efficient sparse coding algorithms[C]. Advances in neural
                information processing systems. 2006: 801-808.
                [157] McCann S, Lowe D G. Local naive bayes nearest neighbor for image classification[C]. Computer
                Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2012: 3650-3656.
                [158] Cai J F, Candès E J, Shen Z. A singular value thresholding algorithm for matrix completion[J].
                SIAM Journal on Optimization, 2010, 20(4): 1956-1982.
                [159] Candes E J, Romberg J K, Tao T. Stable signal recovery from incomplete and inaccurate
                measurements[J]. Communications on pure and applied mathematics, 2006, 59(8): 1207-1223.
                [160] Liu G, Lin Z, Yu Y. Robust subspace segmentation by low-rank representation[C]. Proceedings of the
                27th International Conference on Machine Learning (ICML-10). 2010: 663-670.
                [161] Candes E J, Plan Y. Matrix completion with noise[J]. Proceedings of the IEEE, 2010, 98(6):
                925-936.
                [162] Huang J, Nie F, Huang H, et al. Supervised and projected sparse coding for image
                classification[C]. Twenty-Seventh AAAI Conference on Artificial Intelligence. 2013.
                [163] Zheng M, Bu J, Chen C, et al. Graph regularized sparse coding for image representation[J]. Image
                Processing, IEEE Transactions on, 2011, 20(5): 1327-1336.
                [164] Achanta R, Shaji A, Smith K, et al. Slic superpixels[R]. 2010.
                [165] Georghiades A S, Belhumeur P N, Kriegman D. From few to many: Illumination cone models for face
                recognition under variable lighting and pose[J]. Pattern Analysis and Machine Intelligence, IEEE
                Transactions on, 2001, 23(6): 643-660.
                [166] http://www.cad.zju.edu.cn/home/dengcai/Data/MLData.html
                [167] Fei-Fei L, Fergus R, Perona P. Learning generative visual models from few training examples: An
                incremental bayesian approach tested on 101 object categories[J]. Computer Vision and Image
                Understanding, 2007, 106(1): 59-70.
                [168] Fei-Fei L, Perona P. A bayesian hierarchical model for learning natural scene categories[C].
                Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. IEEE,
                2005, 2: 524-531.
                [169] Turk M, Pentland A. Eigenfaces for recognition[J]. Journal of cognitive neuroscience, 1991, 3(1):
                71-86.
                [170] Yang M, Zhang D, Feng X. Fisher discrimination dictionary learning for sparse representation[C].
                Computer Vision (ICCV), 2011 IEEE International Conference on. IEEE, 2011: 543-550.
                [171] Jiang Z, Lin Z, Davis L S. Learning a discriminative dictionary for sparse coding via label
                consistent K-SVD[C]. Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on. IEEE,
                2011: 1697-1704.
                [172] http://sparselab.stanford.edu/
                [173] Haasdonk B, Keysers D. Tangent distance kernels for support vector machines[C]. ICPR, 2002, 2:
                864-868.
                [174] Huang Y, Huang K, Yu Y, et al. Salient coding for image classification[C]. Computer Vision and
                Pattern Recognition (CVPR), 2011 IEEE Conference on. IEEE, 2011: 1753-1760.
                [175] Pa?ca M. Weakly-supervised discovery of named entities using web search queries[C]. Proceedings of
                the sixteenth ACM conference on Conference on information and knowledge management. ACM, 2007: 683-690.
                [176] Jain A, Pantel P. Identifying comparable entities on the web[C]. Proceedings of the 18th ACM
                conference on Information and knowledge management. ACM, 2009: 1661-1664.
                [177] Li S, Lin C Y, Song Y I, et al. Comparable entity mining from comparative questions[J]. Knowledge
                and Data Engineering, IEEE Transactions on, 2013, 25(7): 1498-1509.
                [178] Jain A, Pennacchiotti M. Open entity extraction from web search query logs[C]. Proceedings of the
                23rd International Conference on Computational Linguistics. Association for Computational Linguistics,
                2010: 510-518.
                [179] Toutanova K, Klein D, Manning C D, et al. Feature-rich part-of-speech tagging with a cyclic
                dependency network[C]. Proceedings of the 2003 Conference of the North American Chapter of the
                Association for Computational Linguistics on Human Language Technology-Volume 1. Association for
                Computational Linguistics, 2003: 173-180.
                [180] Klein D, Manning C D. Fast exact inference with a factored model for natural language parsing[C].
                Advances in neural information processing systems. 2002: 3-10.
                [181] Ahn Y Y, Bagrow J P, Lehmann S. Link communities reveal multiscale complexity in networks[J].
                Nature, 2010, 466(7307): 761-764.
                [182] Wu W, Li H, Wang H, et al. Probase: A probabilistic taxonomy for text understanding[C].
                Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data. ACM, 2012: 481-492.
                [183] Ponzetto S P, Strube M. Deriving a large scale taxonomy from Wikipedia[C]. AAAI. 2007, 7:
                1440-1445.
                [184] Bollacker K, Evans C, Paritosh P, et al. Freebase: a collaboratively created graph database for
                structuring human knowledge[C]. Proceedings of the 2008 ACM SIGMOD international conference on
                Management of data. ACM, 2008: 1247-1250.
                [185] Jang M, Park J, Hwang S. Predictive Mining of Comparable Entities from the Web[C]. AAAI. 2012.
                [186] Cheung J C K, Li X. Sequence clustering and labeling for unsupervised query intent discovery[C].
                Proceedings of the fifth ACM international conference on Web search and data mining. ACM, 2012: 383-392.
                [187] Page L, Brin S, Motwani R, et al. The PageRank citation ranking: Bringing order to the web[J].
                1999.
                [188] http://opennlp.apache.org/
            </A3015>
            <A3015 valueType="7">10907008</A3015>
            <A3015 valueType="7">1d1fd1ce000018c351</A3015>
            <A3015 valueType="7">开放领域信息抽取； 特定领域信息抽取；随机游走算法； 网页排序；图像语义自动标注； 图像分类； 视觉词包；低秩编码</A3015>
            <A3015 valueType="7">提交</A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="4">78</A3015>
            <A3015 valueType="7">工学博士</A3015>
            <A3015 valueType="7">计算机学院</A3015>
            <A3015 valueType="7"></A3015>
            <A3015 valueType="7"></A3015>
        </N23008>
    </N23008>
</N20015>